{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing - Generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = \".\\data\\malevis_train_val_300x300\\\\train\\\\\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to use our images for training and testing, lets use **ImageDataGenerator.flow_from_directory()** which generates batches of normalized tensor image data from the respective data directories.\n",
    "  * **target_size** : Will resize all images to the specified size. I personally chose (64*64) images.\n",
    "  * **batch_size** : Is the size of the batch we will use. In our case, we only have 9339 images, hence setting a batch_size above this won't change anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batches = ImageDataGenerator().flow_from_directory(directory=path_root, target_size=(224,224), batch_size=10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**batches** generated with ImageDataGenerator() is an iterator. Hence, we use next() to go through all its elements and generate a batch of images and labels from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(batches)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets split our model into train and test following a ratio 70% train - 30% test ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs/255.,labels, test_size=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build **ZFNet** model using Keras. This model will have the following layers :\n",
    "\n",
    "* **Convolutional Layer 1** : 96 filters, (7 * 7) kernel size, strides = 2 pixels\n",
    "* **Max Pooling Layer** : (3 * 3) pool size\n",
    "* **Local contrast normalization layers**\n",
    "* **Convolutional Layer 2** : 256 filters, (3 * 3) kernel size\n",
    "* **Max Pooling Layer** : (3 * 3) pool size\n",
    "* **Local contrast normalization layers**\n",
    "* **Convolutional Layer 3** : 384 filters, (3 * 3) kernel size\n",
    "* **Convolutional Layer 4** : 384 filters, (3 * 3) kernel size\n",
    "* **Convolutional Layer 5** : 256 filters, (3 * 3) kernel size\n",
    "* **Max Pooling Layer** : (3 * 3) pool size\n",
    "* **Flatten Layer**\n",
    "* **Dense/Fully Connected Layer** : 4096 Neurons, Relu activation function\n",
    "* **Dense/Fully Connected Layer** : 4096 Neurons, Relu activation function\n",
    "* **Dense/Fully Connected Layer** : num_class Neurons, Softmax activation function\n",
    "\n",
    "**Input shape** : 224 * 224 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, ZeroPadding2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "import tensorflow as tf\n",
    "# from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want **26** classes as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 26"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zfnet():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=96, kernel_size=(7, 7), activation='relu', input_shape=(225, 225, 3), strides=(2, 2)))\n",
    "    model.add(ZeroPadding2D(padding = (1,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=256, kernel_size=(5,5), activation='relu', strides=(2, 2)))\n",
    "    model.add(ZeroPadding2D(padding = (1,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(metrics=['accuracy',\n",
    "                    tf.keras.metrics.Precision(name=\"precision\"),\n",
    "                    tf.keras.metrics.Recall(name=\"recall\")], loss='categorical_crossentropy')\n",
    "    return model\n",
    "Malware_model = zfnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Malware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Malware_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = Malware_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final CNN accuracy: ', scores[1])\n",
    "print('Final CNN precision: ', scores[2])\n",
    "print('Final CNN recall: ', scores[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = Malware_model.predict_classes(X_test, verbose=0)\n",
    "predict_x=Malware_model.predict(X_test) \n",
    "y_pred=np.argmax(predict_x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2 = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "c_matrix = metrics.confusion_matrix(y_test2, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names= batches.class_indices.keys()\n",
    "confusion_matrix(c_matrix, class_names, figsize = (20,7), fontsize=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
